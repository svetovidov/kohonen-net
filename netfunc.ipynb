{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "# -- initial network configuration --\n",
    "\n",
    "def netInit (numFeatures):\n",
    "    \n",
    "    if numFeatures < 1:\n",
    "        print (\"Number of features must be at least 1\")\n",
    "        sys.exit()\n",
    "    weight = np.zeros ((numFeatures, 1))\n",
    "    net = {'numFeatures': numFeatures, 'numClusters': 1, 'maxNumClusters': 15,  'weight': weight, 'disThreshold': 0.85, 'numEpochs': 10, 'learningRate': 0.6, 'rateDecrease': 0.05}\n",
    "    return net\n",
    "\n",
    "\n",
    "# -- learn network on vectors from dataLearn --\n",
    "\n",
    "def netLearn (net, dataLearn):\n",
    "    \n",
    "    # ascertain that # of features equals # of weights per cluster\n",
    "    if len(dataLearn) != len(net['weight']):\n",
    "        print (\"Number of features in training data does not match the number of weight connections per neuron\")\n",
    "        sys.exit()\n",
    "    w = net['weight']\n",
    "    counter = np.zeros(net['maxNumClusters'])\n",
    "    R = np.zeros(net['maxNumClusters']) # vector for Euclidean distances\n",
    "    clustLearn = np.zeros(len(dataLearn[0,:]))\n",
    "    newNet = {}\n",
    "    \n",
    "    # data normalization\n",
    "    for j in range (net['numFeatures']):\n",
    "        maxVal = max(dataLearn[j,:])\n",
    "        for k in range (len(dataLearn[0,:])):\n",
    "            dataLearn[j,k] = dataLearn[j,k] / maxVal\n",
    "    \n",
    "    # learn on all epochs\n",
    "    for i in range(net['numEpochs']):\n",
    "        w_temp = [] # temporary storage for weights\n",
    "        v = net['learningRate'] - net['rateDecrease']*i # learning rate for current epoch\n",
    "        \n",
    "        # learning on all data vectors within epoch\n",
    "        for j in range (len(dataLearn[0,:])):\n",
    "            res = False # label showing absence(False)/presence(True) of weight changes\n",
    "            \n",
    "            # for 1st epoch and 1st learning vector\n",
    "            if (j == 0) and (i == 0):\n",
    "                w[:,j] = dataLearn[:,j] # equate weight values to input values\n",
    "                res = True\n",
    "                clustLearn[j] = 1 # in this case cluster is 1\n",
    "            else:\n",
    "                # count distances between current vector and each cluster\n",
    "                for k in range (len(w[0,:])):\n",
    "                    R[k] = dist.euclidean(dataLearn[:,j], w[:,k])\n",
    "                    \n",
    "                # check if min distance less than threshold\n",
    "                if min(R[np.nonzero(R)]) <= net['disThreshold']:\n",
    "                    t = list(R).index(min(R[np.nonzero(R)])) # index of min distance in vector of distances\n",
    "                    counter[t] += 1\n",
    "                    clustLearn[j] = t + 1\n",
    "                    w_temp = w[:,t]\n",
    "                    s = np.subtract(dataLearn[:,j], w_temp)\n",
    "                    w[:,t] = w_temp + s*v # update weights\n",
    "                    \n",
    "                    # check if weights changed\n",
    "                    if sum (abs(np.subtract(w[:,t], w_temp))) > 0.001: \n",
    "                        res = True\n",
    "                        \n",
    "                # check if reached max number of clusters\n",
    "                elif len(w[0,:]) < net['maxNumClusters']:\n",
    "                    w = np.c_[w, dataLearn[:,j]] # add data column to the end of weight matrix\n",
    "                    res = True\n",
    "                else:\n",
    "                    clustLearn[j] = -1 # set -1 if category has not been found\n",
    "                    res = True\n",
    "                    \n",
    "            # exit if no weight changes occurred in last epoch\n",
    "            if (res == False) and (i == net['numEpochs']-1):\n",
    "                break\n",
    "        if res == False and (i == net['numEpochs']-1):\n",
    "            break\n",
    "            \n",
    "    cl = len(w[0,:])\n",
    "    \n",
    "    # delete unused clusters\n",
    "    for i in range (net['maxNumClusters']-1, -1, -1):\n",
    "        if (counter[i] == 0) and (cl > i):\n",
    "            w = np.delete(w, i, 1)\n",
    "            for j in range(len(clustLearn)):\n",
    "                if clustLearn[j] > (i+1):\n",
    "                    clustLearn[j] -= 1\n",
    "    \n",
    "    # cut empty parts of distance vectors\n",
    "    cl = len(w[0,:])\n",
    "    R = R [:cl]\n",
    "    \n",
    "    # save learned network configuration\n",
    "    net['weight'] = w\n",
    "    net['numClusters'] = cl\n",
    "    net['lastDistances'] = R\n",
    "    newNet = net\n",
    "    return newNet, clustLearn\n",
    "\n",
    "\n",
    "# -- clust vectors from dataCat --\n",
    "\n",
    "def netClust (net, dataCat):\n",
    "    \n",
    "    t = 0\n",
    "    w = net['weight']\n",
    "    R = np.zeros(len(w[0,:]))\n",
    "    clustResult = np.zeros(len(dataCat[0,:]))\n",
    "    \n",
    "    # ascertain that # of features equals # of weights per cluster\n",
    "    if len(dataCat) != len(net['weight']):\n",
    "        print ('\\nNumber of features in testing data does not match the number of weight connections per neuron')\n",
    "        sys.exit()\n",
    "    for j in range (net['numFeatures']):\n",
    "        maxVal = max(dataCat[j,:])\n",
    "        \n",
    "        # normalize test data\n",
    "        for k in range (len(dataCat[0,:])):\n",
    "            dataCat[j,k] = dataCat[j,k] / maxVal\n",
    "    \n",
    "    for j in range (len(dataCat[0,:])):\n",
    "        \n",
    "        # count distances between current vector and each cluster\n",
    "        for k in range (len(w[0,:])):\n",
    "            R[k] = dist.euclidean(dataCat[:,j], w[:,k])\n",
    "        \n",
    "        # determine cluster value\n",
    "        t = list(R).index(min(R[np.nonzero(R)]))\n",
    "        clustResult[j] = t + 1\n",
    "        \n",
    "    return clustResult"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
